{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy zoo image classification - basics with PyTorch\n",
    "\n",
    "> Marc Huertas-Company & Alexandre Boucaud  \n",
    "> Ecole Rodolphe Cledassou 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON COLAB uncomment the line below\n",
    "# #!pip install torch torchvision albumentations datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://astdp.net/euclid-zoo-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON COLAB uncomment the line below\n",
    "# !unzip /content/euclid-zoo-data -d /content/zoo-datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and exploring the datasets\n",
    "\n",
    "The data can be found in https://astdp.net/euclid-zoo-data\n",
    "\n",
    "Unzip it locally and update the `PATH_TO_DATADIR` according to your system.  \n",
    "Otherwise use the second method to load directly from the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "PATH_TO_DATADIR = \"dataset/zoo-data\"\n",
    "# PATH_TO_DATADIR = \"/content/zoo-data\"  # ON COLAB\n",
    "\n",
    "train_set = load_dataset(\"imagefolder\", data_dir=PATH_TO_DATADIR, split=\"train\")\n",
    "test_set = load_dataset(\"imagefolder\", data_dir=PATH_TO_DATADIR, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_set.features['label']\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0]['image'].resize((200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.int2str(train_set[0]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining data augmentations\n",
    "\n",
    "This will use the transformations defined in https://albumentations.ai/docs/ to augment the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "data_augmentation_pipeline = A.Compose([\n",
    "    A.Rotate(limit=180, interpolation=1,\n",
    "                always_apply=True, border_mode=0, value=0),\n",
    "    A.RandomResizedCrop(\n",
    "        height=224,  # after crop resize\n",
    "        width=224,\n",
    "        scale=(0.7, 0.8),  # crop factor\n",
    "        ratio=(0.9, 1.1),  # crop aspect ratio\n",
    "        interpolation=1,  # This is \"INTER_LINEAR\" == BILINEAR interpolation. See: https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html\n",
    "        always_apply=True\n",
    "    ),  # new aspect ratio\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.ToFloat(max_value=255.0, always_apply=True),\n",
    "])    \n",
    "\n",
    "def augment_func(samples):\n",
    "    samples[\"pixel_values\"] = [\n",
    "        data_augmentation_pipeline(image=np.array(image))[\"image\"] for image in samples[\"image\"]\n",
    "    ]\n",
    "    return samples\n",
    "\n",
    "train_set.set_transform(augment_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However we don't want these augmentations to be applied to the test images. We only want to standardize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "standardization_pipeline = A.Compose([\n",
    "    A.Resize(height=224, width=224, interpolation=1), \n",
    "    A.ToFloat(max_value=255.0, always_apply=True),\n",
    "])\n",
    "\n",
    "def standardize_func(samples):\n",
    "    samples[\"pixel_values\"] = [\n",
    "        standardization_pipeline(image=np.array(image))[\"image\"] for image in samples[\"image\"]\n",
    "    ]\n",
    "    return samples\n",
    "\n",
    "test_set.set_transform(standardize_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a convolutional network to extract features from the images from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 4)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function for this classification problem will be a cross entropy loss.\n",
    "\n",
    "We also set up the optimizer for the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training, we can create a dataloader that will take the sample images from the dataset by batch of `batch_size`, apply the data augmentation and feed them to the neural network following a scheme defined in the `collate_fn` function below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([torch.tensor(example[\"pixel_values\"]) for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return  pixel_values.permute(0, 3, 1, 2), labels\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                         shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This is the training script that will run for a number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 3\n",
    "\n",
    "for epoch in range(N_EPOCHS):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 0:\n",
    "            print(f'Epoch {epoch + 1:2d}, batch {i + 1:3d}] | loss: {running_loss / 30:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training we can save the model state into a file so we can load it back again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'convnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load('convnet.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "Finally we can evaluate the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercices\n",
    "\n",
    "You job, if you accept it, is to improve the accuracy of the model.\n",
    "\n",
    "To do so, here are some ideas:\n",
    "- try new data augmentations from the Albumentations package (https://albumentations.ai/docs/)\n",
    "- explore new CNN architectures found on the web (GitHub, Kaggle, arXiv..)\n",
    "- look at the effect of the learning rate, epochs and batch_size on the training loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "euclid-school24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
